{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DEPRECATED**\n",
    "code in this jupyter notebook is out of date, use the python file for the most up to date code\n",
    "though I do like the jupyter shell which is why it's still here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Dependencies\n",
    "%pip install -qU datasets pinecone-client sentence-transformers torch pyngrok cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import pinecone\n",
    "from config import PINECONE_API_KEY\n",
    "\n",
    "#Connect to vector DB\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=\"gcp-starter\"\n",
    ")\n",
    "#basically a table in a db except it's not sql, hardcoded here because\n",
    "# free plan only lets you make one anyways\n",
    "index = pinecone.Index('genghis-khan')\n",
    "\n",
    "# set device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# load the retriever model from huggingface model hub\n",
    "retriever = SentenceTransformer(\n",
    "    \"flax-sentence-embeddings/all_datasets_v3_mpnet-base\", device=device)\n",
    "retriever\n",
    "\n",
    "\n",
    "# load generator model from huggingface\n",
    "tokenizer = BartTokenizer.from_pretrained('vblagoje/bart_lfqa')\n",
    "generator = BartForConditionalGeneration.from_pretrained(\n",
    "    'vblagoje/bart_lfqa').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Helper functions for retrieval and answering\n",
    "\n",
    "# returns the k vectors that most match the query in vector db\n",
    "def query_pinecone(query, top_k):\n",
    "    # generate embeddings for the query\n",
    "    query = retriever.encode([query]).tolist()\n",
    "    # return relevant context vecros from query\n",
    "    context = index.query(query, top_k=top_k, include_metadata=True)\n",
    "    return context\n",
    "\n",
    "\n",
    "# this function checks if relevant passages for the query exists\n",
    "# pinecone gives a \"score\" metric which shows vector similarity \n",
    "def check_relevancy(query):\n",
    "    query = retriever.encode([query]).tolist()\n",
    "    context = index.query(query, top_k=1, include_metadata=True)\n",
    "\n",
    "    # Access the score value\n",
    "    score = context['matches'][0]['score']\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def generate_answer(query, context):\n",
    "    # extract passage_text from Pinecone search result and add the <P> tag\n",
    "    context = [f\"<P> {m['metadata']['passage_text']}\" for m in context]\n",
    "    # concatinate all context passages\n",
    "    context = \" \".join(context)\n",
    "\n",
    "    # contcatinate the query and context passages\n",
    "    input_text = f\"question: {query} context: {context}\"\n",
    "\n",
    "    # tokenize the query to get input_ids\n",
    "    input_tokens = tokenizer([input_text], max_length=1024,\n",
    "                       return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # use generator to predict output ids\n",
    "    ids = generator.generate(\n",
    "        input_tokens[\"input_ids\"], num_beams=2, min_length=20, max_length=100)\n",
    "        \n",
    "    # use tokenizer to decode the output ids\n",
    "    answer = tokenizer.batch_decode(\n",
    "        ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from flask import Flask, request, jsonify, make_response\n",
    "from werkzeug.serving import make_server\n",
    "from pyngrok import ngrok\n",
    "import threading\n",
    "\n",
    "# Create App\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "def run_app():\n",
    "    global server\n",
    "    server = make_server('127.0.0.1', 5000, app)\n",
    "    server.serve_forever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Routes\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "import cohere\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return \"Api works!\"\n",
    "\n",
    "\n",
    "@app.route(\"/test_route\")\n",
    "def test_route():\n",
    "    return jsonify(\"test\")\n",
    "\n",
    "@app.route('/ask', methods=['POST'])\n",
    "def ask():\n",
    "    try:\n",
    "        if request.method == 'POST':\n",
    "            # Get the search query from the form\n",
    "            query = request.form['search_query']\n",
    "\n",
    "            context = query_pinecone(query, top_k=3)\n",
    "            #debug statement to view context and scores\n",
    "            print(context)\n",
    "\n",
    "            relevancy_of_text = check_relevancy(query)\n",
    "            if relevancy_of_text>0.6:\n",
    "                matching_context = context[\"matches\"]\n",
    "                answer = generate_answer(query, matching_context)\n",
    "                citations = [doc[\"metadata\"]['passage_text']\n",
    "                             for doc in matching_context]\n",
    "                return jsonify({\"answer\": answer, \"citations\": citations, \"confidence\":relevancy_of_text})\n",
    "            else:\n",
    "                return jsonify({\"message\": \"No relevant text found\"})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred: \", e)\n",
    "        return jsonify({'error': 'Internal Server Error'}), 500\n",
    "\n",
    "\n",
    "@app.route('/ask_cohere', methods=['POST'])\n",
    "def ask_cohere():\n",
    "    try:\n",
    "        if request.method == 'POST':\n",
    "            # Get the search query from the form\n",
    "            query = request.form['search_query']\n",
    "\n",
    "            context = query_pinecone(query, top_k=3)\n",
    "            #debug statement to view context and scores\n",
    "            print(context)\n",
    "\n",
    "            relevancy_of_text = check_relevancy(query)\n",
    "            if relevancy_of_text > 0.6:\n",
    "                matching_context = context[\"matches\"]\n",
    "                \n",
    "                co = cohere.Client(\n",
    "                    '<<7s5kg565M3eD9WTcX5V9BvSL3R27KoT6JQzUObgp>>')\n",
    "                answer = co.generate(\n",
    "                prompt = f\"answer this question: {query}\\n based on this text {matching_context}\",\n",
    "                stream = True, max_tokens = 99, presence_penalty = 0.3\n",
    "                )\n",
    "\n",
    "                citations = [doc[\"metadata\"]['passage_text']\n",
    "                             for doc in matching_context]\n",
    "                return jsonify({\"answer\": answer, \"citations\": citations, \"confidence\": relevancy_of_text})\n",
    "            else:\n",
    "                return jsonify({\"message\": \"No relevant text found\"})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred: \", e)\n",
    "        return jsonify({'error': 'Internal Server Error'}), 500\n",
    "\n",
    "        \n",
    "@app.route('/vectorize_page', methods=['POST'])\n",
    "\n",
    "# performance: the genghis khan wikipedia page takes around 40 secs\n",
    "def vectorize_page():\n",
    "    try:\n",
    "        # Get the JSON data from the request body\n",
    "        data = request.json\n",
    "        print(\"data: \" + str(data))\n",
    "\n",
    "        # Check if 'url' key exists in the JSON data\n",
    "        if 'name' not in data:\n",
    "            return jsonify({'error': 'The JSON data must contain a \"name\" key'}), 400\n",
    "\n",
    "        index_name = data['name']\n",
    "\n",
    "        if index_name not in pinecone.list_indexes():\n",
    "            pinecone.create_index(\n",
    "                index_name,\n",
    "                dimension=768,\n",
    "                metric=\"cosine\"\n",
    "            )\n",
    "\n",
    "        index = pinecone.Index(index_name)\n",
    "\n",
    "        if 'passage_text' not in data:\n",
    "            return jsonify({'error': 'No passages found'}), 400\n",
    "\n",
    "        passage_texts = data['passage_text']\n",
    "        df = pd.DataFrame({'passage_text': passage_texts})\n",
    "\n",
    "        # Drop rows with less than 2 words\n",
    "        df = df[df['passage_text'].apply(lambda x: len(x.split()) >= 2)]\n",
    "\n",
    "        batch_size = len(df)\n",
    "        emb = retriever.encode(df[\"passage_text\"].tolist()).tolist()\n",
    "        meta = df.to_dict(orient=\"records\")\n",
    "        ids = [f\"{idx}\" for idx in range(len(df))]\n",
    "        to_upsert = list(zip(ids, emb, meta))\n",
    "\n",
    "        index = pinecone.Index(index_name)\n",
    "\n",
    "        for i in tqdm(range(len(to_upsert))):\n",
    "            _ = index.upsert(vectors=[to_upsert[i]])\n",
    "\n",
    "        index_stats = index.describe_index_stats()\n",
    "        return jsonify({'message': f'{index_name} vectorized'})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred: \", e)\n",
    "        return jsonify({'error': 'Internal Server Error'}), 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t=2023-10-01T08:36:16-0400 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=\"/Users/notAdmin/Library/Application Support/ngrok/ngrok.yml\" legacy_path=/Users/notAdmin/.ngrok2/ngrok.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * ngrok tunnel \"NgrokTunnel: \"https://b8f9-37-120-244-62.ngrok-free.app\" -> \"http://localhost:5000\"\" -> \"http://127.0.0.1:5000\"\n"
     ]
    }
   ],
   "source": [
    "# launch server\n",
    "flask_thread = threading.Thread(target=run_app)\n",
    "flask_thread.start()\n",
    "\n",
    "# Open an ngrok tunnel to the HTTP server\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:5000\\\"\".format(public_url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': '70',\n",
      "              'metadata': {'passage_text': 'Map of the Mongol tribes circa '\n",
      "                                           '1207'},\n",
      "              'score': 0.683004141,\n",
      "              'values': []},\n",
      "             {'id': '109',\n",
      "              'metadata': {'passage_text': 'Map of Central Asian Mongol '\n",
      "                                           'campaigns between 1216 and 1223.'},\n",
      "              'score': 0.667707443,\n",
      "              'values': []},\n",
      "             {'id': '29',\n",
      "              'metadata': {'passage_text': 'Genghis Khan (born Temüjin; c. '\n",
      "                                           '1162 – 25 August 1227), also known '\n",
      "                                           'as Chinggis Khan,[a] was the '\n",
      "                                           'founder and first khagan of the '\n",
      "                                           'Mongol Empire, which later became '\n",
      "                                           'the largest contiguous land empire '\n",
      "                                           'in history. Having spent the '\n",
      "                                           'majority of his life uniting the '\n",
      "                                           'Mongol tribes, he launched a '\n",
      "                                           'series of military campaigns that '\n",
      "                                           'conquered large parts of China and '\n",
      "                                           'Central Asia.'},\n",
      "              'score': 0.648688734,\n",
      "              'values': []}],\n",
      " 'namespace': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Oct/2023 08:36:28] \"\u001b[35m\u001b[1mPOST /ask_cohere HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred:  name 'answer' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Oct/2023 08:36:41] \"GET /test_route HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': '70',\n",
      "              'metadata': {'passage_text': 'Map of the Mongol tribes circa '\n",
      "                                           '1207'},\n",
      "              'score': 0.683004141,\n",
      "              'values': []},\n",
      "             {'id': '109',\n",
      "              'metadata': {'passage_text': 'Map of Central Asian Mongol '\n",
      "                                           'campaigns between 1216 and 1223.'},\n",
      "              'score': 0.667707443,\n",
      "              'values': []},\n",
      "             {'id': '29',\n",
      "              'metadata': {'passage_text': 'Genghis Khan (born Temüjin; c. '\n",
      "                                           '1162 – 25 August 1227), also known '\n",
      "                                           'as Chinggis Khan,[a] was the '\n",
      "                                           'founder and first khagan of the '\n",
      "                                           'Mongol Empire, which later became '\n",
      "                                           'the largest contiguous land empire '\n",
      "                                           'in history. Having spent the '\n",
      "                                           'majority of his life uniting the '\n",
      "                                           'Mongol tribes, he launched a '\n",
      "                                           'series of military campaigns that '\n",
      "                                           'conquered large parts of China and '\n",
      "                                           'Central Asia.'},\n",
      "              'score': 0.648688734,\n",
      "              'values': []}],\n",
      " 'namespace': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Oct/2023 08:36:47] \"\u001b[35m\u001b[1mPOST /ask_cohere HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred:  name 'answer' is not defined\n"
     ]
    }
   ],
   "source": [
    "# # Shutdown Api\n",
    "# if server:\n",
    "#     server.shutdown()\n",
    "# # Disconnect the ngrok tunnel\n",
    "# ngrok.disconnect(public_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
